{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "자동차번호판개선-thinning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LooAgXUbdBe_"
      },
      "source": [
        "# 번호판 인식 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J54FphnkdFHh"
      },
      "source": [
        "OpenCV와 tensorflow를 이용한 번호판 인식 프로그램 입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9BgJPmW0dLOp"
      },
      "source": [
        "## 모듈 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM41aRljYS7H"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models, Input, Model\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZXsR6HYdNhk"
      },
      "source": [
        "## MNIST 데이터 불러오기 및 정규화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ6rQKNKa4V6",
        "outputId": "535ae48c-e9c0-48e2-b41b-a973fe50f1e1"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "\n",
        "# 픽셀 값을 0~1 사이로 정규화합니다.\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ei3y_UlwdVHT"
      },
      "source": [
        "## CNN 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wY0nS99YfUI",
        "outputId": "9669acea-ad5b-4036-bc5a-80d69375c977"
      },
      "source": [
        "# CNN 모델을 생성한다.\n",
        "\n",
        "# Convoultion 한 후 Output size 는 다음과 같이 계산된다.\n",
        "# (W - F + 2P) / S + 1\n",
        "# W : 원래 이미지 크기\n",
        "# F : 커널의 크기\n",
        "# P : 패딩의 크기 (패딩은 이미지 바깥에 임의의 값 영역을 추가로 주는 것을 의미. 보통 0으로 주는 Zero-Padding 방식을 사용)\n",
        "# S : Stride의 크기 (커널의 이동 거리. 기본값은 1)\n",
        "\n",
        "# MaxPooling 한 후 Output size 는 다음과 같이 계산된다.\n",
        "# (W - M) / S + 1\n",
        "# W : 원래 이미지의 크기\n",
        "# M : Pooling 커널의 크기\n",
        "# S : Stride의 크기 (Pooling 커널의 이동 거리. Convoultion과 다르게 Pooling의 기본 Stride값은 2 이다.)\n",
        "\n",
        "i = Input(shape=(28, 28, 1)) # 첫번째 층. 입력레이어. 28*28*1의 이미지\n",
        "x = layers.Conv2D(32, (3, 3), activation='relu')(i) # 3 * 3 커널 32개를 지니는 Convolution 레이어\n",
        "\n",
        "                                       # 출력 : (28 - 3 + 0) / 1 + 1 = 26 이고 32개의 커널이 존재하므로 최종적으로 26 * 26 * 32 의 output size를 가진다.\n",
        "\n",
        "x = layers.MaxPooling2D((2, 2))(x) # 각 26 * 26 에서 2 * 2의 크기를 지니는 커널을 이동시켜가며 가장 큰 값을 뽑아내는 Max Pooling 레이어\n",
        "\n",
        "                                       # 출력 : (26 - 2) / 2 + 1 = 13 이고 들어온 input이 32개 이므로 최종적으로 13 * 13 * 32 의 output size를 가진다.\n",
        "\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x) # 64개의 3 * 3 커널을 사용하는 Convolution 레이어\n",
        "\n",
        "# 출력 : (13 - 3 + 0) / 1 + 1 =  11, 결과 : 11 * 11 * 64\n",
        "\n",
        "x = layers.MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# 출력 : (11 - 2) / 2 + 1 = 5, 결과 : 5 * 5 * 64\n",
        "\n",
        "x = layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "\n",
        "# 출력 : (5 - 3 + 0) / 1 + 1 = 3, 결과 : 3 * 3 * 64\n",
        "\n",
        "x = layers.Flatten()(x) # 완전연결신경망으로 데이터를 전달하기위해서 이미지를 1차원 벡터로 펼쳐주는 층. 9 * 9 * 64 = 5184의 1차원 벡터를 생성함.\n",
        "\n",
        "x2 = layers.Dense(64, activation='relu')(x) # 64개의 노드를 지니는 일반 층\n",
        "y = layers.Dense(10, activation='softmax')(x2) # 10개의 노드를 지니는 일반층(class 분류 결과를 보여주기위해 softmax 활성화 함수 사용)\n",
        "model = Model(inputs=i,outputs=y)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-D-qQpZdYSo"
      },
      "source": [
        "## 모델 컴파일 및 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0yTb646TZiD0",
        "outputId": "59632c01-a29a-43bf-a62d-576de82b1245"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 42s 7ms/step - loss: 0.1425 - accuracy: 0.9556\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0466 - accuracy: 0.9855\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0333 - accuracy: 0.9898\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 13s 7ms/step - loss: 0.0268 - accuracy: 0.9917\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 12s 6ms/step - loss: 0.0205 - accuracy: 0.9934\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8cdbb37ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4MZQjRTddSU"
      },
      "source": [
        "## 실제 번호판 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dML76EfnYd4Z"
      },
      "source": [
        "image_list = os.listdir('./imgs') # imgs라는 폴더 안의 모든 파일명을 가져옵니다.\n",
        "\n",
        "roi_list = [] # 실제 프로그램 내에서 사용될 리스트.\n",
        "labels = [] # 실제 프로그램 내에서 사용될 target값.\n",
        "\n",
        "for img in image_list:\n",
        "  roi = cv.imread('./imgs/'+img) # imgs 폴더에 있는 이미지 하나씩 불러옴\n",
        "  roi_gray = cv.cvtColor(roi,cv.COLOR_BGR2GRAY) # 흑백으로 변환\n",
        "  _, thr = cv.threshold(roi_gray, thresh=0.0, maxval=255.0, type=cv.THRESH_BINARY | cv.THRESH_OTSU)# 2진화 수행\n",
        "  thr = cv.ximgproc.thinning(thr)\n",
        "  # thr = cv.adaptiveThreshold(roi_gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 11, 2) # 이진화 시킴. 방식은 apdative threshold\n",
        "  thr = cv.resize(thr, dsize=(28, 28), interpolation=cv.INTER_AREA) # 28 * 28 으로 이미지 크기 변환\n",
        "  thr = thr / 255.0 # 0~1 사이의 값으로 정규화\n",
        "  thr = thr.reshape((28,28,1)) # 딥러닝 모듈에 집어넣기 위해서 2차원 흑백이미지를 3차원으로 변환\n",
        "\n",
        "  roi_list.append(thr) # 리스트에 추가\n",
        "  labels.append(int(img[0])) # 파일명의 맨 앞글자(숫자)로 라벨을 지정하고 리스트에 추가\n",
        "\n",
        "train_images2 = np.array(roi_list) # 학습될 이미지 numpy array로 변환\n",
        "train_labels2 = np.array(labels) # 학습될 라벨 numpy array로 변환"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mz6yvisKdkSv"
      },
      "source": [
        "## 전이 학습을 위한 Weight Freezing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr4c9YgmbDwN"
      },
      "source": [
        "x.trainable = False # Convolution Layer들은 학습시키지 않는다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4kPzZn3ds_Y"
      },
      "source": [
        "## MNIST데이터로 학습된 모델에 번호판 데이터로 전이학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJ_EItita795",
        "outputId": "42512648-031c-4814-e38b-5a4d3fc5b61b"
      },
      "source": [
        "model.fit(train_images2, train_labels2, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "20/20 [==============================] - 1s 13ms/step - loss: 1.4623 - accuracy: 0.5426\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.4061 - accuracy: 0.8864\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2011 - accuracy: 0.9432\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 0s 10ms/step - loss: 0.1781 - accuracy: 0.9385\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 0s 8ms/step - loss: 0.1082 - accuracy: 0.9685\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8cd0043790>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCQigJUHdzYo"
      },
      "source": [
        "## 임의의 데이터로 성능테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPnzUzBFh1l7",
        "outputId": "75ebc0d6-6b90-4637-be30-2ffec1706275"
      },
      "source": [
        "roi = cv.imread(\"./imgs/8.png\")\n",
        "\n",
        "roi_gray = cv.cvtColor(roi,cv.COLOR_BGR2GRAY)\n",
        "_, thr = cv.threshold(roi_gray, thresh=0.0, maxval=255.0, type=cv.THRESH_BINARY | cv.THRESH_OTSU)# 2진화 수행\n",
        "thr = cv.ximgproc.thinning(thr)\n",
        "# thr = cv.adaptiveThreshold(roi_gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 11, 2) # 이진화 시킴. 방식은 apdative threshold\n",
        "thr = cv.resize(thr, dsize=(28, 28), interpolation=cv.INTER_AREA)\n",
        "thr = thr.reshape((28,28,1))\n",
        "thr = thr / 255.0\n",
        "\n",
        "np.argmax(model.predict(np.expand_dims(thr,0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8DaODGyd27e"
      },
      "source": [
        "## 학습한 모델 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BzLpCIbdFI-x"
      },
      "source": [
        "model.save('my_cnn_model_new.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}