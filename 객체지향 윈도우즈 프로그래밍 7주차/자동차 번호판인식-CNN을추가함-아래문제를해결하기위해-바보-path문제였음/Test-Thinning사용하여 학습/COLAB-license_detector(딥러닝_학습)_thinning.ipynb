{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "license_detector(딥러닝 학습)-thinning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KdBWlRJQ85s0"
      },
      "source": [
        "# 번호판 인식 학습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmQYdGy49DLu"
      },
      "source": [
        "OpenCV와 tensorflow를 이용한 번호판 인식 프로그램 입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtEJJAtG9AmW"
      },
      "source": [
        "## 모듈 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4qPhl4L8vI9"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWVJ-qIY9W9F"
      },
      "source": [
        "## 이미지 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD0y6xDx9cMG"
      },
      "source": [
        "image_list = os.listdir('./imgs') # imgs라는 폴더 안의 모든 파일명을 가져옵니다.\n",
        "\n",
        "roi_list = [] # 실제 프로그램 내에서 사용될 리스트.\n",
        "labels = [] # 실제 프로그램 내에서 사용될 target값.\n",
        "\n",
        "for img in image_list:\n",
        "  roi = cv.imread('./imgs/'+img) # imgs 폴더에 있는 이미지 하나씩 불러옴\n",
        "  roi_gray = cv.cvtColor(roi,cv.COLOR_BGR2GRAY) # 흑백으로 변환\n",
        "  _, thr = cv.threshold(roi_gray, thresh=0.0, maxval=255.0, type=cv.THRESH_BINARY | cv.THRESH_OTSU)# 2진화 수행\n",
        "  thr = cv.ximgproc.thinning(thr)\n",
        "  # thr = cv.adaptiveThreshold(roi_gray, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY_INV, 11, 2) # 이진화 시킴. 방식은 apdative threshold\n",
        "  thr = cv.resize(thr, dsize=(28, 28), interpolation=cv.INTER_AREA) # 28 * 28 으로 이미지 크기 변환\n",
        "  thr = thr / 255.0 # 0~1 사이의 값으로 정규화\n",
        "  thr = thr.reshape((28,28,1)) # 딥러닝 모듈에 집어넣기 위해서 2차원 흑백이미지를 3차원으로 변환\n",
        "\n",
        "  roi_list.append(thr) # 리스트에 추가\n",
        "  labels.append(int(img[0])) # 파일명의 맨 앞글자(숫자)로 라벨을 지정하고 리스트에 추가\n",
        "\n",
        "train_images = np.array(roi_list) # 학습될 이미지 numpy array로 변환\n",
        "train_labels = np.array(labels) # 학습될 라벨 numpy array로 변환"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGVji4zMX1dt"
      },
      "source": [
        "## CNN 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6g_5YN5lX3j2",
        "outputId": "41a888ab-ab5d-4652-859c-7ba5a0f37ff1"
      },
      "source": [
        "# CNN 모델을 생성한다.\n",
        "\n",
        "# Convoultion 한 후 Output size 는 다음과 같이 계산된다.\n",
        "# (W - F + 2P) / S + 1\n",
        "# W : 원래 이미지 크기\n",
        "# F : 커널의 크기\n",
        "# P : 패딩의 크기 (패딩은 이미지 바깥에 임의의 값 영역을 추가로 주는 것을 의미. 보통 0으로 주는 Zero-Padding 방식을 사용)\n",
        "# S : Stride의 크기 (커널의 이동 거리. 기본값은 1)\n",
        "\n",
        "# MaxPooling 한 후 Output size 는 다음과 같이 계산된다.\n",
        "# (W - M) / S + 1\n",
        "# W : 원래 이미지의 크기\n",
        "# M : Pooling 커널의 크기\n",
        "# S : Stride의 크기 (Pooling 커널의 이동 거리. Convoultion과 다르게 Pooling의 기본 Stride값은 2 이다.)\n",
        "\n",
        "model = models.Sequential() # 모델 생성\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1))) # 첫번째 층. 입력은 28*28*1의 이미지, 3 * 3 커널 32개를 지니는 Convolution 레이어\n",
        "\n",
        "                                       # 출력 : (28 - 3 + 0) / 1 + 1 = 26 이고 32개의 커널이 존재하므로 최종적으로 26 * 26 * 32 의 output size를 가진다.\n",
        "\n",
        "model.add(layers.MaxPooling2D((2, 2))) # 각 26 * 26 에서 2 * 2의 크기를 지니는 커널을 이동시켜가며 가장 큰 값을 뽑아내는 Max Pooling 레이어\n",
        "\n",
        "                                       # 출력 : (26 - 2) / 2 + 1 = 13 이고 들어온 input이 32개 이므로 최종적으로 13 * 13 * 32 의 output size를 가진다.\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu')) # 64개의 3 * 3 커널을 사용하는 Convolution 레이어\n",
        "\n",
        "# 출력 : (13 - 3 + 0) / 1 + 1 =  11, 결과 : 11 * 11 * 64\n",
        "\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "\n",
        "# 출력 : (11 - 2) / 2 + 1 = 5.5, 결과 : 5 * 5 * 64\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "# 출력 : (5 - 3 + 0) / 1 + 1 = 3, 결과 : 3 * 3 * 64\n",
        "\n",
        "model.add(layers.Flatten()) # 완전연결신경망으로 데이터를 전달하기위해서 이미지를 1차원 벡터로 펼쳐주는 층. 9 * 9 * 64 = 5184의 1차원 벡터를 생성함.\n",
        "model.add(layers.Dense(64, activation='relu')) # 64개의 노드를 지니는 일반 층\n",
        "model.add(layers.Dense(10, activation='softmax')) # 10개의 노드를 지니는 일반층(class 분류 결과를 보여주기위해 softmax 활성화 함수 사용)\n",
        "model.summary() # 생성된 모델 모양 출력"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtpmtEpbX8Ss"
      },
      "source": [
        "## 모델 컴파일 및 훈련"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVaLNk2xX-Ys",
        "outputId": "8de316f2-805e-46da-88fc-b502b90960ae"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "20/20 [==============================] - 30s 13ms/step - loss: 2.1608 - accuracy: 0.3912\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 1.2411 - accuracy: 0.6278\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 0s 6ms/step - loss: 0.6102 - accuracy: 0.8265\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.3671 - accuracy: 0.9054\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 0s 7ms/step - loss: 0.2682 - accuracy: 0.9306\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3e20077990>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvHiZJDvbiW9"
      },
      "source": [
        "## 학습한 모델 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVJLDxMpboEV"
      },
      "source": [
        "model.save('my_cnn_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}